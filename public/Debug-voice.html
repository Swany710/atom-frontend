<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Debug - Atom</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: #0a0a0a;
            color: #ffffff;
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }

        .container {
            max-width: 800px;
            width: 100%;
            background: #1a1a1a;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0, 255, 157, 0.1);
            border: 1px solid #333;
        }

        h1 {
            color: #00ff9d;
            text-align: center;
            margin-bottom: 30px;
        }

        .voice-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(45deg, #00ff9d, #00bcd4);
            color: white;
            font-size: 1.2em;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 20px auto;
            box-shadow: 0 4px 15px rgba(0, 255, 157, 0.3);
        }

        .voice-button.recording {
            background: linear-gradient(45deg, #ff4444, #ff6b6b);
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .status {
            text-align: center;
            padding: 15px;
            margin: 20px 0;
            border-radius: 10px;
            font-weight: bold;
        }

        .status.success { background: rgba(0, 255, 157, 0.1); color: #00ff9d; }
        .status.error { background: rgba(255, 68, 68, 0.1); color: #ff4444; }
        .status.processing { background: rgba(255, 193, 7, 0.1); color: #ffc107; }
        .status.listening { background: rgba(0, 188, 212, 0.1); color: #00bcd4; }

        .debug-section {
            background: #2a2a2a;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .debug-info {
            background: #333;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
            font-family: monospace;
            font-size: 0.9em;
            color: #ccc;
            max-height: 300px;
            overflow-y: auto;
            white-space: pre-wrap;
        }

        .response-display {
            background: #1e3a8a;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
            color: #93c5fd;
            font-family: monospace;
            white-space: pre-wrap;
            max-height: 200px;
            overflow-y: auto;
        }

        .conversation {
            background: #2a2a2a;
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
        }

        .message {
            margin: 15px 0;
            padding: 12px 18px;
            border-radius: 18px;
            max-width: 80%;
            word-wrap: break-word;
        }

        .message.user {
            background: #00ff9d;
            color: #000;
            margin-left: auto;
            text-align: right;
        }

        .message.assistant {
            background: #333;
            color: #fff;
            margin-right: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üîç Voice Debug - Atom</h1>
        
        <!-- Voice Interface -->
        <button id="voiceBtn" class="voice-button" onclick="toggleRecording()">
            üé§ Start
        </button>

        <div id="status" class="status">Ready to debug voice processing</div>

        <!-- Debug Information -->
        <div class="debug-section">
            <h3>üìä Audio Recording Debug</h3>
            <div id="audioDebug" class="debug-info">Waiting for recording...</div>
        </div>

        <div class="debug-section">
            <h3>üåê Backend Response Debug</h3>
            <div id="responseDebug" class="response-display">Waiting for response...</div>
        </div>

        <!-- Conversation Display -->
        <div id="conversation" class="conversation"></div>

        <!-- Full Debug Log -->
        <div class="debug-section">
            <h3>üìù Complete Debug Log</h3>
            <div id="debug" class="debug-info"></div>
        </div>
    </div>

    <script>
        // Backend Configuration
        const BACKEND_URL = 'https://atom-backend-production-8a1e.up.railway.app';
        
        // Voice Recording Variables
        let isRecording = false;
        let mediaRecorder = null;
        let audioChunks = [];

        // UI Elements
        const voiceBtn = document.getElementById('voiceBtn');
        const statusDiv = document.getElementById('status');
        const conversationDiv = document.getElementById('conversation');
        const debugDiv = document.getElementById('debug');
        const audioDebugDiv = document.getElementById('audioDebug');
        const responseDebugDiv = document.getElementById('responseDebug');

        // Update Status Function
        function updateStatus(message, type = 'info') {
            statusDiv.textContent = message;
            statusDiv.className = `status ${type}`;
            debugLog(`[STATUS ${type.toUpperCase()}] ${message}`);
        }

        // Debug Log Function
        function debugLog(message) {
            const timestamp = new Date().toLocaleTimeString();
            debugDiv.innerHTML += `<div>[${timestamp}] ${message}</div>`;
            debugDiv.scrollTop = debugDiv.scrollHeight;
            console.log(`[DEBUG ${timestamp}] ${message}`);
        }

        // Audio Debug Function
        function audioDebugLog(message) {
            const timestamp = new Date().toLocaleTimeString();
            audioDebugDiv.innerHTML += `[${timestamp}] ${message}\n`;
            audioDebugDiv.scrollTop = audioDebugDiv.scrollHeight;
        }

        // Response Debug Function
        function responseDebugLog(message) {
            responseDebugDiv.textContent = message;
            responseDebugDiv.scrollTop = responseDebugDiv.scrollHeight;
        }

        // Add Message to Conversation
        function addMessage(sender, message) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}`;
            messageDiv.textContent = message;
            conversationDiv.appendChild(messageDiv);
            conversationDiv.scrollTop = conversationDiv.scrollHeight;
        }

        // Voice Recording Functions
        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            try {
                updateStatus('Requesting microphone access...', 'processing');
                audioDebugLog('Requesting microphone access...');
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 44100
                    }
                });

                debugLog('Microphone access granted');
                audioDebugLog('Microphone access granted');
                
                audioChunks = [];
                
                // Try different mime types for compatibility
                let mimeType = 'audio/webm;codecs=opus';
                if (!MediaRecorder.isTypeSupported(mimeType)) {
                    mimeType = 'audio/webm';
                    if (!MediaRecorder.isTypeSupported(mimeType)) {
                        mimeType = 'audio/mp4';
                        if (!MediaRecorder.isTypeSupported(mimeType)) {
                            mimeType = ''; // Let browser choose
                        }
                    }
                }

                const options = mimeType ? { mimeType } : {};
                mediaRecorder = new MediaRecorder(stream, options);
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        debugLog(`Audio chunk received: ${event.data.size} bytes`);
                        audioDebugLog(`Audio chunk received: ${event.data.size} bytes, type: ${event.data.type}`);
                    }
                };
                
                mediaRecorder.onstop = processAudioRecording;
                
                mediaRecorder.start();
                isRecording = true;
                
                voiceBtn.textContent = '‚èπÔ∏è Stop';
                voiceBtn.classList.add('recording');
                updateStatus('üé§ Recording... Speak now!', 'listening');
                
                audioDebugLog(`Recording started with mime type: ${mimeType || 'auto'}`);
                
            } catch (error) {
                updateStatus(`Microphone error: ${error.message}`, 'error');
                debugLog(`Recording error: ${error.message}`);
                audioDebugLog(`Recording error: ${error.message}`);
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            
            if (mediaRecorder?.stream) {
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
            }
            
            isRecording = false;
            voiceBtn.textContent = 'üé§ Start';
            voiceBtn.classList.remove('recording');
            updateStatus('Processing audio...', 'processing');
            
            debugLog('Recording stopped');
            audioDebugLog('Recording stopped');
        }

        // Process Audio Recording with Enhanced Debugging
        async function processAudioRecording() {
            try {
                debugLog('Processing audio recording...');
                audioDebugLog('Processing audio recording...');
                
                if (audioChunks.length === 0) {
                    throw new Error('No audio data recorded');
                }

                const audioBlob = new Blob(audioChunks, { 
                    type: audioChunks[0].type || 'audio/webm' 
                });
                
                debugLog(`Audio blob created: ${audioBlob.size} bytes, type: ${audioBlob.type}`);
                audioDebugLog(`Audio blob created: ${audioBlob.size} bytes, type: ${audioBlob.type}`);
                
                if (audioBlob.size === 0) {
                    throw new Error('Audio recording is empty');
                }
                
                updateStatus('Sending to backend...', 'processing');
                
                // Create FormData for voice upload
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.webm');
                formData.append('userId', 'debug-user');
                
                debugLog('Sending request to backend...');
                audioDebugLog('Sending request to backend...');
                
                const response = await fetch(`${BACKEND_URL}/api/v1/ai/voice-command1`, {
                    method: 'POST',
                    body: formData
                });

                debugLog(`Backend response: ${response.status} ${response.statusText}`);
                audioDebugLog(`Backend response: ${response.status} ${response.statusText}`);

                // Debug response headers
                const headers = {};
                for (let [key, value] of response.headers.entries()) {
                    headers[key] = value;
                }
                responseDebugLog(`Response Headers:\n${JSON.stringify(headers, null, 2)}`);

                if (response.ok) {
                    const result = await response.json();
                    debugLog('Backend response received successfully');
                    
                    // Show complete response
                    responseDebugLog(`Response Body:\n${JSON.stringify(result, null, 2)}`);
                    
                    // Check response structure
                    if (result.mode === 'error') {
                        throw new Error(`Backend error: ${result.message}`);
                    }
                    
                    if (result.transcription) {
                        addMessage('user', `üé§ "${result.transcription}"`);
                        audioDebugLog(`Transcription: "${result.transcription}"`);
                    }
                    if (result.message) {
                        addMessage('assistant', result.message);
                    }
                    
                    updateStatus('Voice command processed successfully!', 'success');
                    
                } else {
                    const errorText = await response.text();
                    responseDebugLog(`Error Response:\n${errorText}`);
                    throw new Error(`Backend error: ${response.status} - ${errorText}`);
                }
                
            } catch (error) {
                updateStatus(`Voice processing failed: ${error.message}`, 'error');
                debugLog(`Processing error: ${error.message}`);
                audioDebugLog(`Processing error: ${error.message}`);
                responseDebugLog(`Error: ${error.message}`);
                addMessage('assistant', `Error: ${error.message}`);
            }
        }

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            updateStatus('Debug interface loaded - enhanced logging enabled', 'success');
            debugLog('Debug interface initialized with enhanced logging');
        });
    </script>
</body>
</html>